{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing stellar population models\n",
    "\n",
    "Paintbox is particularly designed to model the observed spectrum, i.e.,\n",
    "the flux from stars as a function of the wavelength, of galaxies where\n",
    "stars are not individually resolved. In these cases, the most important\n",
    "ingredient to describe the stellar features in observations are stellar\n",
    "population models, which describe the properties of an emsemble of stars\n",
    "with different properties, e.g., ages, metallicities, etc. Several groups of\n",
    "astronomers distribute their models for free for users, either publicily\n",
    "or under request. However, there is no single standard way of\n",
    "distributing stellar population models, so we have to prepare the data\n",
    "from the models *before* using **paintbox**. Moreover, in practical\n",
    "applications, we also require the models to be tunned according to the \n",
    "scientific requirements of the modeling as a way to minimize the \n",
    "(often expensive) number of computations depending on the resolution of \n",
    "the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING EMILES stellar populations templates\n",
    "\n",
    "Stellar populations models from the MILES library can be obtained in a variety of ways in their [website](http://research.iac.es/proyecto/miles//pages/stellar-libraries/miles-library.php). For this example, we will use the packages [astropy](https://www.astropy.org) to handle FITS fiels and tables, and the [pPXF]([ppxf](https://pypi.org/project/ppxf/) for rebinning the data to a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits \n",
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use a set of single stellar population (SSP) templates of the E-MILES models (version 11) produced with BASTI isochrones and assuming a Chabrier initial mass function, which can be downloaded in a tarball from their public ftp link available [in their website](http://miles.iac.es/) (EMILES_BASTI_BASE_CH_FITS.tar.gz, 95 Mb). After downloading the data, it is necessary to unpack the tarfile (preferentially into a subdirectory, which we name emiles_v11), containing the 636 SSP spectra in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "emiles_dir = os.path.join(os.getcwd(), \"emiles_v11\")\n",
    "w1 = 2600 # Minimum wavelength\n",
    "w2 = 10000 # Maximum wavelength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [MILES name convention](http://research.iac.es/proyecto/miles/pages/ssp-models/name-convention.php) to read the files with the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miles_filename(specrange, imf, imfslope, metal, age):\n",
    "    \"\"\" Returns the name of a fits file in the MILES library according\n",
    "    to the name convention. \"\"\"\n",
    "    msign = \"p\" if metal >= 0. else \"m\"\n",
    "    azero = \"0\" if age < 10. else \"\"\n",
    "    return \"{0}{1}{2:.2f}Z{3}{4:.2f}T{5}{6:02.4f}\" \\\n",
    "            \"_iTp0.00_baseFe.fits\".format(specrange, imf, \\\n",
    "            imfslope, msign, abs(metal), azero, age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we produce a list containing all the spectra that we are going to use in our analysis (filenames), and we also produce an astropy [Table object](https://docs.astropy.org/en/stable/api/astropy.table.Table.html#astropy.table.Table) storing the parameters of the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "specrange = \"E\" # options: \"E\", \"M\", \"B\", \"R\", \"C\"\n",
    "imf = \"ch\" # options: \"un\", \"bi\", \"ku\", \"kb\", \"ch\"\n",
    "imfslope = 1.3\n",
    "# Values of metallicities and ages available for BASTI isochrones\n",
    "Zs = np.array([-0.96, -0.66, -0.35, -0.25, 0.06, 0.15,  0.26,  0.4]) \n",
    "Ts = np.linspace(1., 14., 27) # Using only ages > 1 Gyr\n",
    "ssps_grid = np.array(np.meshgrid(Ts, Zs)).T.reshape(-1, 2)\n",
    "nssps = len(ssps_grid)\n",
    "filenames = []\n",
    "for t, z in ssps_grid:\n",
    "    filenames.append(miles_filename(specrange, imf, imfslope, z, t))\n",
    "params = Table(ssps_grid, names=[\"T\", \"Z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the information in the header of one spectrum to determine the wavelength range (which is always the same for a given set of models). Notice that the wavelength range covered by the EMILES models is large (from the near-UV to the IR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = fits.getheader(os.path.join(emiles_dir, filenames[0]))\n",
    "wave = (h['CRVAL1'] + h['CDELT1'] * (np.arange((h['NAXIS1'])) + 1 - h['CRPIX1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to trim and/or rebin the model spectra. We need to trim the data to cover only the spectral region of the observed data. Notice, however, that we should always have extra coverage in the models, preferentially on both edges of the spectra, if we are also modeling the kynematics of the galaxy, and also to avoid problems at the edges of the models owing to convolutions (below I use 500 Angstrom, but this can be optimized for a galaxy according to their redshift). We may also rebin the data, either to have the same wavelength dispersion of the observations, or to a logarithmic scale to model the kinematics. We use the pPXF for this purpose, assuming a velocity scale for the rebinning of 200 km/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "velscale = 200\n",
    "extra_wave = 500\n",
    "idx = np.where((wave >= w1 - extra_wave) & (wave <= w2 + extra_wave))\n",
    "wave = wave[idx] # Trimming wavelength array\n",
    "\n",
    "# Using first spectrum to get array size after rebbining\n",
    "flux = fits.getdata(os.path.join(emiles_dir, filenames[0]))[idx]\n",
    "wrange = [wave[0], wave[-1]]\n",
    "newflux, logLam, velscale = ppxf_util.log_rebin(wrange, flux, \n",
    "                                                 velscale=velscale)\n",
    "# Loop to trim and rebin spectra\n",
    "ssps = np.zeros((nssps, len(newflux)))\n",
    "for i, filename in enumerate(filenames):\n",
    "    flambda = fits.getdata(os.path.join(emiles_dir, filename))[idx]\n",
    "    flux_log = ppxf_util.log_rebin(wrange, flambda, velscale=velscale)[0]\n",
    "    ssps[i] = flux_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to store the processed data into a FITS file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emiles_chabrier_w2600_10000_vel200.fits\n"
     ]
    }
   ],
   "source": [
    "hdu1 = fits.PrimaryHDU(ssps)\n",
    "hdu1.header[\"EXTNAME\"] = \"SSPS\"\n",
    "hdu2 = fits.BinTableHDU(params)\n",
    "hdu2.header[\"EXTNAME\"] = \"PARAMS\"\n",
    "hdu3 = fits.BinTableHDU(Table([logLam], names=[\"loglam\"]))\n",
    "hdu3.header[\"EXTNAME\"] = \"WAVE\"\n",
    "hdulist = fits.HDUList([hdu1, hdu2, hdu3])\n",
    "output = \"emiles_chabrier_w{}_{}_vel{}.fits\".format(w1, w2, velscale)\n",
    "hdulist.writeto(output, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular example, we will obtain a multi-extension FITS file named \"emiles_chabrier_w2600_10000_vel200.fits\", which contains the 2D array with the models, a parameter table, and an 1D array with the wavelength array. Notice that, in practice, if often necessary to degrade the model spectra to match the resolution of the observations, which can be performed with the task paintbox.utils.broad2res. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing CvD models\n",
    "\n",
    "Models from the [Conroy and van Dokkum (2012)](https://ui.adsabs.harvard.edu/abs/2012ApJ...747...69C/abstract) and [Conroy et al. (2018)](https://ui.adsabs.harvard.edu/abs/2018ApJ...854..139C/abstract), a.k.a. CvD models, can be obtained under request to the authors. Similar to the MILES models, CvD are also distributed as SSP models with varying ages, metallicities, and IMFs, but also provide response functions that allow the variation of several individual elements, e.g.,  C, N, O, Mg, Si, Ca, Ti, and Fe. Below we show how to handle these models for **paintbox**. For this example, we use the SSP models computed with the [VCJ stellar library](https://ui.adsabs.harvard.edu/abs/2017ApJS..230...23V/abstract) version 8, and the response functions from Conroy et al. (2018) version 3. In this example, we use [SpectRes](https://spectres.readthedocs.io/en/latest/} to perform the rebinning of the models, as it can handle arbitrary wavelength dispersions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from astropy.table import Table, vstack\n",
    "from astropy.io import fits\n",
    "from ppxf import ppxf_util\n",
    "from spectres import spectres\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a function to handle the SSP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_VCJ17(data_dir, wave, output, redo=False):\n",
    "    \"\"\" Prepare templates for SSP models from Villaume et al. (2017).\n",
    "    \n",
    "        Parameters\n",
    "    ----------\n",
    "    data_dir: str\n",
    "        Path to the SSP models.\n",
    "    wave: np.array\n",
    "        Wavelength dispersion.\n",
    "    output: str\n",
    "        Name of the output file (a multi-extension FITS file)\n",
    "    \n",
    "    \"\"\"\n",
    "    if os.path.exists(output) and not redo:\n",
    "        return\n",
    "    specs = sorted(os.listdir(data_dir))\n",
    "    nimf = 16\n",
    "    imfs = 0.5 + np.arange(nimf) / 5\n",
    "    x2s, x1s=  np.stack(np.meshgrid(imfs, imfs)).reshape(2, -1)\n",
    "    ssps, params = [], []\n",
    "    for spec in tqdm(specs, desc=\"Processing SSP files\"):\n",
    "        T = float(spec.split(\"_\")[3][1:])\n",
    "        Z = float(spec.split(\"_\")[4][1:-8].replace(\"p\", \"+\").replace(\n",
    "                    \"m\", \"-\"))\n",
    "        data = np.loadtxt(os.path.join(data_dir, spec))\n",
    "        w = data[:,0]\n",
    "        for i, (x1, x2) in enumerate(zip(x1s, x2s)):\n",
    "            params.append(Table([[Z], [T], [x1], [x2]],\n",
    "                                names=[\"Z\", \"Age\", \"x1\", \"x2\"]))\n",
    "            ssp = data[:, i+1]\n",
    "            newssp = spectres(wave, w, ssp)\n",
    "            ssps.append(newssp)\n",
    "    ssps = np.array(ssps)\n",
    "    params = vstack(params)\n",
    "    hdu1 = fits.PrimaryHDU(ssps)\n",
    "    hdu1.header[\"EXTNAME\"] = \"SSPS\"\n",
    "    params = Table(params)\n",
    "    hdu2 = fits.BinTableHDU(params)\n",
    "    hdu2.header[\"EXTNAME\"] = \"PARAMS\"\n",
    "    # Making wavelength array\n",
    "    hdu3 = fits.BinTableHDU(Table([wave], names=[\"wave\"]))\n",
    "    hdu3.header[\"EXTNAME\"] = \"WAVE\"\n",
    "    hdulist = fits.HDUList([hdu1, hdu2, hdu3])\n",
    "    hdulist.writeto(output, overwrite=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we define a function to produce the models for the response functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_response_functions(data_dir, wave, outprefix, redo=False):\n",
    "    \"\"\" Prepare response functions from CvD models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: str\n",
    "        Path to the response function files\n",
    "    wave: np.array\n",
    "        Wavelength dispersion.\n",
    "    outprefix: str\n",
    "        First part of the name of the response function output files. The\n",
    "        response functions are stored in different files for different\n",
    "        elements, named \"{}_{}.fits\".format(outprefix, element).\n",
    "\n",
    "    \"\"\"\n",
    "    specs = sorted(os.listdir(data_dir))\n",
    "    # Read one spectrum to get name of columns\n",
    "    with open(os.path.join(data_dir, specs[0])) as f:\n",
    "        header = f.readline().replace(\"#\", \"\")\n",
    "    fields = [_.strip() for _ in header.split(\",\")]\n",
    "    fields[fields.index(\"C+\")] = \"C+0.15\"\n",
    "    fields[fields.index(\"C-\")] = \"C-0.15\"\n",
    "    fields[fields.index(\"T+\")] = \"T+50\"\n",
    "    fields[fields.index(\"T-\")] = \"T-50\"\n",
    "    fields = [\"{}0.3\".format(_) if _.endswith(\"+\") else _ for _ in fields ]\n",
    "    fields = [\"{}0.3\".format(_) if _.endswith(\"-\") else _ for _ in fields]\n",
    "    elements = set([_.split(\"+\")[0].split(\"-\")[0] for _ in fields if\n",
    "                    any(c in _ for c in [\"+\", \"-\"])])\n",
    "    signal = [\"+\", \"-\"]\n",
    "    for element in tqdm(elements, desc=\"Preparing response functions\"):\n",
    "        output = \"{}_{}.fits\".format(outprefix, element.replace(\"/\", \"\"))\n",
    "        if os.path.exists(output) and not redo:\n",
    "            continue\n",
    "        params = []\n",
    "        rfs = []\n",
    "        for spec in specs:\n",
    "            T = float(spec.split(\"_\")[2][1:])\n",
    "            Z = float(spec.split(\"_\")[3].split(\".abun\")[0][1:].replace(\n",
    "                      \"p\", \"+\").replace(\"m\", \"-\"))\n",
    "            data = np.loadtxt(os.path.join(data_dir, spec))\n",
    "            w = data[:,0]\n",
    "            fsun = data[:,1]\n",
    "            # Adding solar response\n",
    "            p = Table([[Z], [T], [0.]], names=[\"Z\", \"Age\", element])\n",
    "            rf = np.ones(len(wave))\n",
    "            rfs.append(rf)\n",
    "            params.append(p)\n",
    "            # Adding non-solar responses\n",
    "            for sign in signal:\n",
    "                name = \"{}{}\".format(element, sign)\n",
    "                cols = [(i,f) for i, f in enumerate(fields) if f.startswith(\n",
    "                    name)]\n",
    "                for i, col in cols:\n",
    "                    val = float(\"{}1\".format(sign)) * float(col.split(sign)[1])\n",
    "                    t = Table([[Z], [T], [val]], names=[\"Z\", \"Age\", element])\n",
    "                    params.append(t)\n",
    "                    rf = data[:, i] / fsun\n",
    "                    newrf= spectres(wave, w, rf)\n",
    "                    rfs.append(newrf)\n",
    "        rfs = np.array(rfs)\n",
    "        params = vstack(params)\n",
    "        hdu1 = fits.PrimaryHDU(rfs)\n",
    "        hdu1.header[\"EXTNAME\"] = \"SSPS\"\n",
    "        params = Table(params)\n",
    "        hdu2 = fits.BinTableHDU(params)\n",
    "        hdu2.header[\"EXTNAME\"] = \"PARAMS\"\n",
    "        # Making wavelength array\n",
    "        hdu3 = fits.BinTableHDU(Table([wave], names=[\"wave\"]))\n",
    "        hdu3.header[\"EXTNAME\"] = \"WAVE\"\n",
    "        hdulist = fits.HDUList([hdu1, hdu2, hdu3])\n",
    "        hdulist.writeto(output, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, for near-infrared observations, the above routines can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing response functions: 100%|██████████| 21/21 [02:29<00:00,  7.13s/it]\n"
     ]
    }
   ],
   "source": [
    "w1 = 8000\n",
    "w2 = 13000\n",
    "velscale = 200\n",
    "# Using pPXF to set a log dispersion\n",
    "logLam = ppxf_util.log_rebin([w1, w2], np.ones(10), velscale=velscale)[1]\n",
    "wave = np.exp(logLam)\n",
    "# Preparing SSP models\n",
    "models_dir = \"/home/kadu/Dropbox/SPINS/CvD18/\" # Directory where models are stored\n",
    "ssps_dir = os.path.join(models_dir, \"VCJ_v8\") \n",
    "wdir = os.getcwd()\n",
    "output = os.path.join(wdir, \"VCJ17_varydoublex_wifis.fits\")\n",
    "prepare_VCJ17(ssps_dir, wave, output)\n",
    "# Preparing response functions\n",
    "rfs_dir = os.path.join(models_dir, \"RFN_v3\")\n",
    "outprefix = os.path.join(rfs_dir, \"C18_rfs_wifis\")\n",
    "prepare_response_functions(rfs_dir, wave, outprefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
