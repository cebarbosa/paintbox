{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing stellar population models\n",
    "\n",
    "Paintbox is particularly designed to model the observed spectrum, i.e.,\n",
    "the flux from stars as a function of the wavelength, of galaxies where\n",
    "stars are not individually resolved. In these cases, the most important\n",
    "ingredient to describe the stellar features in observations are stellar\n",
    "population models, which describe the properties of an emsemble of stars\n",
    "with different properties, e.g., ages, metallicities, etc. Several groups of\n",
    "astronomers distribute their models for free for users, either publicily\n",
    "or under request. However, these models are distributed in different \n",
    "ways, and we have to deal with the input models accordingly before \n",
    "their use with **paintbox**. The examples below indicate how to deal with\n",
    "some popular stellar populations models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EMILES stellar population models\n",
    "\n",
    "Stellar populations models from the MILES library can be obtained in a variety of ways in their [website](http://research.iac.es/proyecto/miles//pages/stellar-libraries/miles-library.php). For this example, we will use the packages [astropy](https://www.astropy.org) to handle FITS fiels and tables, and the [pPXF]([ppxf](https://pypi.org/project/ppxf/) for rebinning the data to a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits \n",
    "from astropy.table import Table\n",
    "from ppxf import ppxf_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use a set of single stellar population (SSP) templates of the E-MILES models (version 11) produced with BASTI isochrones and assuming a Chabrier initial mass function, which can be downloaded in a tarball from their public ftp link available [in their website](http://miles.iac.es/) (EMILES_BASTI_BASE_CH_FITS.tar.gz, 95 Mb). After downloading the data, it is necessary to unpack the tarfile (preferentially into a subdirectory, which we name emiles_v11), containing the 636 SSP spectra in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emiles_dir = \"/home/kadu/Dropbox/SSPs/emiles_v11\"\n",
    "w1 = 2600 # Minimum wavelength\n",
    "w2 = 10000 # Maximum wavelength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [MILES name convention](http://research.iac.es/proyecto/miles/pages/ssp-models/name-convention.php) to read the files with the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miles_filename(specrange, imf, imfslope, metal, age):\n",
    "    \"\"\" Returns the name of a fits file in the MILES library according\n",
    "    to the name convention. \"\"\"\n",
    "    msign = \"p\" if metal >= 0. else \"m\"\n",
    "    azero = \"0\" if age < 10. else \"\"\n",
    "    return \"{0}{1}{2:.2f}Z{3}{4:.2f}T{5}{6:02.4f}\" \\\n",
    "            \"_iTp0.00_baseFe.fits\".format(specrange, imf, \\\n",
    "            imfslope, msign, abs(metal), azero, age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we produce a list containing all the spectra that we are going to use in our analysis (filenames), and we also produce an astropy [Table object](https://docs.astropy.org/en/stable/api/astropy.table.Table.html#astropy.table.Table) storing the parameters of the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "specrange = \"E\" # options: \"E\", \"M\", \"B\", \"R\", \"C\"\n",
    "imf = \"ch\" # options: \"un\", \"bi\", \"ku\", \"kb\", \"ch\"\n",
    "imfslope = 1.3\n",
    "# Values of metallicities and ages available for BASTI isochrones\n",
    "Zs = np.array([-0.96, -0.66, -0.35, -0.25, 0.06, 0.15,  0.26,  0.4]) \n",
    "Ts = np.linspace(1., 14., 27) # Using only ages > 1 Gyr\n",
    "ssps_grid = np.array(np.meshgrid(Ts, Zs)).T.reshape(-1, 2)\n",
    "nssps = len(ssps_grid)\n",
    "filenames = []\n",
    "for t, z in ssps_grid:\n",
    "    filenames.append(miles_filename(specrange, imf, imfslope, z, t))\n",
    "params = Table(ssps_grid, names=[\"T\", \"Z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the information in the header of one spectrum to determine the wavelength range (which is always the same for a given set of models). Notice that the wavelength range covered by the EMILES models is large (from the near-UV to the IR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = fits.getheader(os.path.join(emiles_dir, filenames[0]))\n",
    "wave = (h['CRVAL1'] + h['CDELT1'] * (np.arange((h['NAXIS1'])) + 1 - h['CRPIX1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to trim and/or rebin the model spectra. We need to trim the data to cover only the spectral region of the observed data. Notice, however, that we should always have extra coverage in the models, preferentially on both edges of the spectra, if we are also modeling the kynematics of the galaxy, and also to avoid problems at the edges of the models owing to convolutions (below I use 500 Angstrom, but this can be optimized for a galaxy according to their redshift). We may also rebin the data, either to have the same wavelength dispersion of the observations, or to a logarithmic scale to model the kinematics. We use the pPXF for this purpose, assuming a velocity scale for the rebinning of 200 km/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "velscale = 200\n",
    "extra_wave = 500\n",
    "idx = np.where((wave >= w1 - extra_wave) & (wave <= w2 + extra_wave))\n",
    "wave = wave[idx] # Trimming wavelength array\n",
    "\n",
    "# Using first spectrum to get array size after rebbining\n",
    "flux = fits.getdata(os.path.join(emiles_dir, filenames[0]))[idx]\n",
    "wrange = [wave[0], wave[-1]]\n",
    "newflux, logLam, velscale = ppxf_util.log_rebin(wrange, flux, \n",
    "                                                 velscale=velscale)\n",
    "# Loop to trim and rebin spectra\n",
    "ssps = np.zeros((nssps, len(newflux)))\n",
    "for i, filename in enumerate(filenames):\n",
    "    flambda = fits.getdata(os.path.join(emiles_dir, filename))[idx]\n",
    "    flux_log = ppxf_util.log_rebin(wrange, flambda, velscale=velscale)[0]\n",
    "    ssps[i] = flux_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to store the processed data into a FITS file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu1 = fits.PrimaryHDU(ssps)\n",
    "hdu1.header[\"EXTNAME\"] = \"SSPS\"\n",
    "hdu2 = fits.BinTableHDU(params)\n",
    "hdu2.header[\"EXTNAME\"] = \"PARAMS\"\n",
    "hdu3 = fits.BinTableHDU(Table([logLam], names=[\"loglam\"]))\n",
    "hdu3.header[\"EXTNAME\"] = \"WAVE\"\n",
    "hdulist = fits.HDUList([hdu1, hdu2, hdu3])\n",
    "output = \"emiles_chabrier_w{}_{}_vel{}.fits\".format(w1, w2, velscale)\n",
    "hdulist.writeto(output, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular example, we will obtain a multi-extension FITS file named \"emiles_chabrier_w2600_10000_vel200.fits\", which contains the 2D array with the models, a parameter table, and an 1D array with the wavelength array. Notice that, in practice, if often necessary to degrade the model spectra to match the resolution of the observations, which can be performed with the task paintbox.utils.broad2res. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CvD stellar population models\n",
    "\n",
    "Models from the [Conroy and van Dokkum (2012)](https://ui.adsabs.harvard.edu/abs/2012ApJ...747...69C/abstract) and [Conroy et al. (2018)](https://ui.adsabs.harvard.edu/abs/2018ApJ...854..139C/abstract), a.k.a. CvD models, can be obtained under request to the authors. Similar to the MILES models, CvD are also distributed as SSP models with varying ages, metallicities, and IMFs, but also provide response functions that allow the variation of several individual elements, e.g.,  C, N, O, Mg, Si, Ca, Ti, and Fe. In this cases, To handle these models, we use the utility class `CvD18`, built from the basic `paintbox` classes, to handle the input files and produce spectra with any combination of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'disp2vel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9a90b9563309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaintbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCvD18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/paintbox/paintbox/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdisp2vel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'disp2vel'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from paintbox.utils import CvD18\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory where you store your models \n",
    "base_dir = \"/home/kadu/Dropbox/SSPs/CvD18\"\n",
    "# Indicating the filenames of the SSP models\n",
    "ssps_dir = os.path.join(base_dir, \"VCJ_v8\")\n",
    "ssp_files = glob.glob(os.path.join(ssps_dir, \"VCJ*.s100\"))\n",
    "# Indicating the filenames for the response functions\n",
    "rfs_dir = os.path.join(base_dir, \"RFN_v3\")\n",
    "rf_files = glob.glob(os.path.join(rfs_dir, \"atlas_ssp*.s100\"))\n",
    "# Defining an arbitrary wavelength region in the near IR\n",
    "w1, w2 = 8000, 13000 # Setting the wavelength window\n",
    "sigma = 300 # Velocity dispersion of the output models\n",
    "wave = np.arange(w1, w2)\n",
    "outdir = os.path.join(os.getcwd(), \"CvD18_test\")\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "outname = \"CvD18_test\"\n",
    "ssp = CvD18(wave, ssp_files=ssp_files, rf_files=rf_files, sigma=sigma,\n",
    "                  outdir=outdir, outname=outname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code needs to prepare the templates in the first time a execution is performed, but the models can be saved to disk (with the option store=True) for quick loading after the fist time they are called. The result is an object that can be easily used to call CvD models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'Age', 'x1', 'x2', 'Ba', 'C', 'Ca', 'Co', 'Cr', 'Cu', 'Eu', 'Fe', 'K', 'Mg', 'Mn', 'N', 'Na', 'Ni', 'Si', 'Sr', 'Ti', 'V']\n"
     ]
    }
   ],
   "source": [
    "# Checking the parameter names\n",
    "print(ssp.parnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all the options and methods available in the documentation of CvD18 for more details. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
