{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing stellar population models\n",
    "\n",
    "Paintbox is particularly designed to model the observed spectrum, i.e.,\n",
    "the flux from stars as a function of the wavelength, of galaxies where\n",
    "stars are not individually resolved. In these cases, the most important\n",
    "ingredient to describe the stellar features in observations are stellar\n",
    "population models, which describe the properties of an emsemble of stars\n",
    "with different properties, e.g., ages, metallicities, etc. Several groups of\n",
    "astronomers distribute their models for free for users, either publicily\n",
    "or under request. However, there is no single standard way of\n",
    "distributing stellar population models, so we have to prepare the data\n",
    "from the models *before* using **paintbox**. Moreover, in practical\n",
    "applications, we also require the models to be tunned according to the \n",
    "scientific requirements of the modeling as a way to minimize the \n",
    "(often expensive) number of computations depending on the resolution of \n",
    "the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING EMILES stellar populations templates\n",
    "\n",
    "Stellar populations models from the MILES library can be obtained in a variety of ways in their [website](http://research.iac.es/proyecto/miles//pages/stellar-libraries/miles-library.php). For this example, we will use the packages [astropy](https://www.astropy.org) to handle FITS fiels and tables, and the [pPXF]([ppxf](https://pypi.org/project/ppxf/) for rebinning the data to a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits \n",
    "from astropy.table import Table\n",
    "from ppxf import ppxf_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use a set of single stellar population (SSP) templates of the E-MILES models (version 11) produced with BASTI isochrones and assuming a Chabrier initial mass function, which can be downloaded in a tarball from their public ftp link available [in their website](http://miles.iac.es/) (EMILES_BASTI_BASE_CH_FITS.tar.gz, 95 Mb). After downloading the data, it is necessary to unpack the tarfile (preferentially into a subdirectory, which we name emiles_v11), containing the 636 SSP spectra in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emiles_dir = \"/home/kadu/Dropbox/SSPs/emiles_v11\"\n",
    "w1 = 2600 # Minimum wavelength\n",
    "w2 = 10000 # Maximum wavelength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [MILES name convention](http://research.iac.es/proyecto/miles/pages/ssp-models/name-convention.php) to read the files with the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miles_filename(specrange, imf, imfslope, metal, age):\n",
    "    \"\"\" Returns the name of a fits file in the MILES library according\n",
    "    to the name convention. \"\"\"\n",
    "    msign = \"p\" if metal >= 0. else \"m\"\n",
    "    azero = \"0\" if age < 10. else \"\"\n",
    "    return \"{0}{1}{2:.2f}Z{3}{4:.2f}T{5}{6:02.4f}\" \\\n",
    "            \"_iTp0.00_baseFe.fits\".format(specrange, imf, \\\n",
    "            imfslope, msign, abs(metal), azero, age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we produce a list containing all the spectra that we are going to use in our analysis (filenames), and we also produce an astropy [Table object](https://docs.astropy.org/en/stable/api/astropy.table.Table.html#astropy.table.Table) storing the parameters of the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "specrange = \"E\" # options: \"E\", \"M\", \"B\", \"R\", \"C\"\n",
    "imf = \"ch\" # options: \"un\", \"bi\", \"ku\", \"kb\", \"ch\"\n",
    "imfslope = 1.3\n",
    "# Values of metallicities and ages available for BASTI isochrones\n",
    "Zs = np.array([-0.96, -0.66, -0.35, -0.25, 0.06, 0.15,  0.26,  0.4]) \n",
    "Ts = np.linspace(1., 14., 27) # Using only ages > 1 Gyr\n",
    "ssps_grid = np.array(np.meshgrid(Ts, Zs)).T.reshape(-1, 2)\n",
    "nssps = len(ssps_grid)\n",
    "filenames = []\n",
    "for t, z in ssps_grid:\n",
    "    filenames.append(miles_filename(specrange, imf, imfslope, z, t))\n",
    "params = Table(ssps_grid, names=[\"T\", \"Z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the information in the header of one spectrum to determine the wavelength range (which is always the same for a given set of models). Notice that the wavelength range covered by the EMILES models is large (from the near-UV to the IR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = fits.getheader(os.path.join(emiles_dir, filenames[0]))\n",
    "wave = (h['CRVAL1'] + h['CDELT1'] * (np.arange((h['NAXIS1'])) + 1 - h['CRPIX1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to trim and/or rebin the model spectra. We need to trim the data to cover only the spectral region of the observed data. Notice, however, that we should always have extra coverage in the models, preferentially on both edges of the spectra, if we are also modeling the kynematics of the galaxy, and also to avoid problems at the edges of the models owing to convolutions (below I use 500 Angstrom, but this can be optimized for a galaxy according to their redshift). We may also rebin the data, either to have the same wavelength dispersion of the observations, or to a logarithmic scale to model the kinematics. We use the pPXF for this purpose, assuming a velocity scale for the rebinning of 200 km/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "velscale = 200\n",
    "extra_wave = 500\n",
    "idx = np.where((wave >= w1 - extra_wave) & (wave <= w2 + extra_wave))\n",
    "wave = wave[idx] # Trimming wavelength array\n",
    "\n",
    "# Using first spectrum to get array size after rebbining\n",
    "flux = fits.getdata(os.path.join(emiles_dir, filenames[0]))[idx]\n",
    "wrange = [wave[0], wave[-1]]\n",
    "newflux, logLam, velscale = ppxf_util.log_rebin(wrange, flux, \n",
    "                                                 velscale=velscale)\n",
    "# Loop to trim and rebin spectra\n",
    "ssps = np.zeros((nssps, len(newflux)))\n",
    "for i, filename in enumerate(filenames):\n",
    "    flambda = fits.getdata(os.path.join(emiles_dir, filename))[idx]\n",
    "    flux_log = ppxf_util.log_rebin(wrange, flambda, velscale=velscale)[0]\n",
    "    ssps[i] = flux_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to store the processed data into a FITS file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu1 = fits.PrimaryHDU(ssps)\n",
    "hdu1.header[\"EXTNAME\"] = \"SSPS\"\n",
    "hdu2 = fits.BinTableHDU(params)\n",
    "hdu2.header[\"EXTNAME\"] = \"PARAMS\"\n",
    "hdu3 = fits.BinTableHDU(Table([logLam], names=[\"loglam\"]))\n",
    "hdu3.header[\"EXTNAME\"] = \"WAVE\"\n",
    "hdulist = fits.HDUList([hdu1, hdu2, hdu3])\n",
    "output = \"emiles_chabrier_w{}_{}_vel{}.fits\".format(w1, w2, velscale)\n",
    "hdulist.writeto(output, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular example, we will obtain a multi-extension FITS file named \"emiles_chabrier_w2600_10000_vel200.fits\", which contains the 2D array with the models, a parameter table, and an 1D array with the wavelength array. Notice that, in practice, if often necessary to degrade the model spectra to match the resolution of the observations, which can be performed with the task paintbox.utils.broad2res. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CvD models\n",
    "\n",
    "Models from the [Conroy and van Dokkum (2012)](https://ui.adsabs.harvard.edu/abs/2012ApJ...747...69C/abstract) and [Conroy et al. (2018)](https://ui.adsabs.harvard.edu/abs/2018ApJ...854..139C/abstract), a.k.a. CvD models, can be obtained under request to the authors. Similar to the MILES models, CvD are also distributed as SSP models with varying ages, metallicities, and IMFs, but also provide response functions that allow the variation of several individual elements, e.g.,  C, N, O, Mg, Si, Ca, Ti, and Fe. Below we show how to handle these models using **paintbox** utilities. For this example, we use the SSP models computed with the [Extended IRTF Spectral Library](https://ui.adsabs.harvard.edu/abs/2017ApJS..230...23V/abstract) version 8, and the response functions from Conroy et al. (2018) version 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from paintbox.utils.CvD_utils import CvD18\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory where you store your models \n",
    "base_dir = \"/home/kadu/Dropbox/SSPs/CvD18\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to point out the location of the models in our computer. To make things simple, I store all SSP models from VCJ library in a subdirectory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicating the name of the SSP models\n",
    "ssps_dir = os.path.join(base_dir, \"VCJ_v8\")\n",
    "ssp_files = glob.glob(os.path.join(ssps_dir, \"VCJ*.s100\"))\n",
    "# Preparing response functions\n",
    "rfs_dir = os.path.join(base_dir, \"RFN_v3\")\n",
    "rf_files = glob.glob(os.path.join(rfs_dir, \"atlas_ssp*.s100\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the data to a convenient wavelength dispersion and to store the models in a single FITS file for later use, we use the paintbox.prepare_VCJ routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an arbitrary wavelength region in the near IR\n",
    "w1, w2 = 8000, 13000 # Setting the wavelength window\n",
    "sigma = 300 # Velocity dispersion of the output models\n",
    "wave = np.arange(w1, w2)\n",
    "outdir = os.path.join(os.getcwd(), \"CVD18_test\")\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "outname = \"CvD18_test\"\n",
    "ssp = CvD18(wave, ssp_files=ssp_files, rf_files=rf_files, sigma=sigma,\n",
    "                  outdir=outdir, outname=outname, nssps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code needs to prepare the templates in the first time a execution is performed, but the models can be saved to disk (with the option store=True) for quick loading after the fist time they are called. The result is an object that can be easily used to call CvD models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w_1', 'Z_1', 'Age_1', 'x1_1', 'x2_1', 'Ba_1', 'C_1', 'Ca_1', 'Co_1', 'Cr_1', 'Cu_1', 'Eu_1', 'Fe_1', 'K_1', 'Mg_1', 'Mn_1', 'N_1', 'Na_1', 'Ni_1', 'Si_1', 'Sr_1', 'Ti_1', 'V_1', 'w_2', 'Z_2', 'Age_2', 'x1_2', 'x2_2', 'Ba_2', 'C_2', 'Ca_2', 'Co_2', 'Cr_2', 'Cu_2', 'Eu_2', 'Fe_2', 'K_2', 'Mg_2', 'Mn_2', 'N_2', 'Na_2', 'Ni_2', 'Si_2', 'Sr_2', 'Ti_2', 'V_2']\n",
      "{'Z': (-1.5, 0.2), 'Age': (1.0, 13.0), 'x1': (0.5, 3.5), 'x2': (0.5, 3.5), 'Ba': (-0.3, 0.3), 'C': (-0.15, 0.15), 'Ca': (-0.3, 0.3), 'Co': (0.0, 0.3), 'Cr': (0.0, 0.3), 'Cu': (0.0, 0.3), 'Eu': (0.0, 0.3), 'Fe': (-0.3, 0.3), 'K': (0.0, 0.3), 'Mg': (-0.3, 0.3), 'Mn': (0.0, 0.3), 'N': (-0.3, 0.3), 'Na': (-0.3, 0.9), 'Ni': (0.0, 0.3), 'Si': (-0.3, 0.3), 'Sr': (0.0, 0.3), 'Ti': (-0.3, 0.3), 'V': (0.0, 0.3)}\n"
     ]
    }
   ],
   "source": [
    "# Checking the parameter names\n",
    "print(ssp.parnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all the options and methods available in the documentation of CvD18. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
